{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec-Wiki-words-250-with-normalization\n",
    "\n",
    "Tensorflow 2.0\n",
    "\n",
    "### Pretrained model\n",
    "Download and unzip the model [Wiki-words-250-with-normalization](https://tfhub.dev/google/Wiki-words-250-with-normalization/2) at a convenient location.\n",
    "\n",
    "Note that I have saved the model at /Users/abhay.shukla/Wiki-words-250-with-normalization/2 and therefore module_url is set to that directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import itertools\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh\n",
    "import bokeh.models\n",
    "import bokeh.plotting\n",
    "from tensorflow_text import SentencepieceTokenizer\n",
    "import sklearn.metrics.pairwise\n",
    "from simpleneighbors import SimpleNeighbors\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretrained model and define function which returns the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_url = '/Users/abhay.shukla/Wiki-words-250-with-normalization/2'\n",
    "model = hub.load(module_url)\n",
    "\n",
    "def embed_text(input):\n",
    "    return model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vocab = pd.read_csv(\"/Users/abhay.shukla/Wiki-words-250-with-normalization/2/assets/tokens.txt\", sep=\"\\n\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1009374, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vocab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>702436</th>\n",
       "      <td>Tonyukuk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413568</th>\n",
       "      <td>Luckily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73579</th>\n",
       "      <td>Beaufils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707298</th>\n",
       "      <td>Trejo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63046</th>\n",
       "      <td>Baikalfinansgrup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779536</th>\n",
       "      <td>Zaknafein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204710</th>\n",
       "      <td>Ecclesiazusae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164831</th>\n",
       "      <td>Cyrtopodium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862160</th>\n",
       "      <td>grapplers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500794</th>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0\n",
       "702436          Tonyukuk\n",
       "413568           Luckily\n",
       "73579           Beaufils\n",
       "707298             Trejo\n",
       "63046   Baikalfinansgrup\n",
       "779536         Zaknafein\n",
       "204710     Ecclesiazusae\n",
       "164831       Cyrtopodium\n",
       "862160         grapplers\n",
       "500794           Numeric"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vocab.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vocab_list = model_vocab.iloc[:, 0].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vocab_list = [str(w) for w in model_vocab_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../word2vec/data/train.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(x):\n",
    "    res = None\n",
    "    res = re.sub('\\t', ' ', x)\n",
    "    res = re.sub('\\n', ' ', res)\n",
    "    res = re.sub('\\r', ' ', res)\n",
    "    res = re.sub('\"', '', res)\n",
    "    res = re.sub(\"'\", '', res)\n",
    "    res = re.sub(\"[#0-9()\\\"+-,&.\\[\\]@*/?!:%}{;`#=|$^\\\\\\\\]\", \" \", res)\n",
    "    res = re.sub(\"[\\s]+\", \" \", res)\n",
    "    res = res.lower()\n",
    "    res = res.strip()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['clean_comment'] = train['comment_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  211062\n"
     ]
    }
   ],
   "source": [
    "comment_data = train['clean_comment'].values\n",
    "comment_data = [x.split(' ') for x in comment_data]\n",
    "vocab = Counter(itertools.chain(*comment_data))\n",
    "vocab_list = list(vocab.keys())\n",
    "print(\"Vocabulary size: \", len(vocab_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['explanation',\n",
       " 'why',\n",
       " 'the',\n",
       " 'edits',\n",
       " 'made',\n",
       " 'under',\n",
       " 'my',\n",
       " 'username',\n",
       " 'hardcore',\n",
       " 'metallica']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embed_text(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(211062, 250)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211062/211062 [1:26:04<00:00, 40.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building comment index with 40 trees...\n",
      "CPU times: user 1h 26min, sys: 32.9 s, total: 1h 26min 33s\n",
      "Wall time: 1h 26min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embedding_dimensions = embeddings.shape[1]\n",
    "params = dict(n = 40, metric='dot', dims=embedding_dimensions)\n",
    "embedding_lookup = SimpleNeighbors(dims=params['dims'], metric=params['metric'])\n",
    "\n",
    "for i in trange(embeddings.shape[0]):\n",
    "    embedding_lookup.add_one(vocab_list[i], embeddings[i])\n",
    "\n",
    "# embedding_lookup.feed(zip(vocab_list, embeddings))\n",
    "\n",
    "print('Building comment index with {} trees...'.format(params['n']))\n",
    "embedding_lookup.build(n=params['n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2273"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list.index('jan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['jan',\n",
       " '-jan',\n",
       " 'jan-',\n",
       " 'jan-jun',\n",
       " 'jan-bart',\n",
       " 'jan-peder',\n",
       " 'geert-jan',\n",
       " 'marisa_magnatta_jan_',\n",
       " 'yo-ho',\n",
       " 'gaa-fai']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picked_word_text = 'jan'\n",
    "print(picked_word_text)\n",
    "embedding_lookup.neighbors(item=picked_word_text, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moron\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['idiot',\n",
       " 'faggot-loving',\n",
       " 'arrogant-believes',\n",
       " 'we-sing-dance-steal-things',\n",
       " 'silly',\n",
       " 'ugly-duckling-theorem',\n",
       " 'rant-',\n",
       " 'boys_do_cry',\n",
       " 'fat-fuck',\n",
       " 'lazy']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picked_word_text = 'moron'\n",
    "print(picked_word_text)\n",
    "embedding_lookup.neighbors(item=picked_word_text, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookup_annoy_model/lookup_annoy_word_model_dims250_metricdot_n40.annoy\n"
     ]
    }
   ],
   "source": [
    "model_write_dir = 'lookup_annoy_model'\n",
    "if not os.path.exists(model_write_dir):\n",
    "    os.makedirs(model_write_dir)\n",
    "    \n",
    "model_name = 'lookup_annoy_word_model_{}.annoy'.format(\"_\".join(sorted([p[0]+str(p[1]) for p in params.items()])))\n",
    "model_file_path = os.path.join(model_write_dir, model_name)\n",
    "print(model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_lookup.save(model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(prefix):\n",
    "    \"\"\"Restores a previously-saved index.\n",
    "\n",
    "    This class method restores a previously-saved index using the specified\n",
    "    file prefix.\n",
    "\n",
    "    :param prefix: prefix used when saving\n",
    "    :returns: SimpleNeighbors object restored from specified files\n",
    "    \"\"\"\n",
    "    import pickle\n",
    "    with open(prefix + \"-data.pkl\", \"rb\") as fh:\n",
    "        data = pickle.load(fh)\n",
    "    newobj = SimpleNeighbors(\n",
    "        dims=data['dims'],\n",
    "        metric=data['metric'],\n",
    "        backend=data['_backend_class']\n",
    "    )\n",
    "    newobj.id_map = data['id_map']\n",
    "    newobj.corpus = data['corpus']\n",
    "    newobj.i = data['i']\n",
    "    newobj.built = data['built']\n",
    "    newobj.backend.load(prefix + \".idx\")\n",
    "    return newobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_lookup_ = load(model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moron\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['idiot',\n",
       " 'faggot-loving',\n",
       " 'arrogant-believes',\n",
       " 'we-sing-dance-steal-things',\n",
       " 'silly',\n",
       " 'ugly-duckling-theorem',\n",
       " 'rant-',\n",
       " 'boys_do_cry',\n",
       " 'fat-fuck',\n",
       " 'lazy']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picked_word_text = 'moron'\n",
    "print(picked_word_text)\n",
    "embedding_lookup_.neighbors(item=picked_word_text, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
